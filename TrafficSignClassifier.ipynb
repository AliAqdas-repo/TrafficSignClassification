{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\nimport pickle\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Directories\ntrainDir=\"../input/traffic-signs-preprocessed/train.pickle\"\nvalidDir=\"/kaggle/input/traffic-signs-preprocessed/valid.pickle\"\ntestDir=\"/kaggle/input/traffic-signs-preprocessed/test.pickle\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading Pickle Files\ntrainHand=open(trainDir,'rb')\ntrainHand=pickle.load(trainHand)\n#print(trainHand)\ntestHand=open(testDir,'rb')\ntestHand=pickle.load(testHand)\nvalidHand=open(validDir,'rb')\nvalidHand=pickle.load(validHand)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracting labels and images from pickled data\ntrain_images, train_labels= trainHand['features'],trainHand['labels'] #imagesize(37499,32,32,3) label_size=(37499,)\ntest_images, test_labels= testHand['features'],testHand['labels'] \nvalid_images, valid_labels= validHand['features'],validHand['labels'] \nclass_types=len(set(train_labels))\nprint(len(train_images))\n#plt.imshow(images[3000])\n#plt.show()","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'trainHand' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-63acb47e595b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# extracting labels and images from pickled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrainHand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainHand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#imagesize(37499,32,32,3) label_size=(37499,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtestHand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestHand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalidHand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidHand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclass_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'trainHand' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizing Images\ntrain_images=train_images/255\ntest_images=test_images/255\nvalid_images=valid_images/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Not used in the provided code\n# Extra feature for preprocessing images\nimport cv2\n'''def preProc(images):\n    grayScaled=[cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)/255 for image in images]\n    \n    return grayScaled\n\ntrain_images=preProc(train_images)\ntest_images=preProc(test_images)\nvalid_images=preProc(valid_images)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displays Image\nplt.imshow(train_images[7000])\nplt.show()\n#print(len(train_images[7000]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TensorFlow Sequential Model\nmodel=tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation='relu'),\n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dense(class_types,activation='softmax')\n])\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creates Batches of Input Data\ndef batchData(features,labels,BATCH_SIZE):\n    X_items=[]\n    tempX=[]\n    Y_items=[]\n    tempY=[]\n    for items in features:\n        tempX+=[items]\n        if len(tempX)==BATCH_SIZE:\n            X_items+=tempX\n            tempX=[]\n    for items in labels:\n        tempY+=[items]\n        if len(tempY)==BATCH_SIZE:    \n            Y_items+=tempY\n            tempY=[]\n    return X_items,Y_items\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Batches using batchData Function\ntrainData, trainLabels = batchData(train_images,train_labels,64)\nvalidData, validLabels = batchData(valid_images,valid_labels,64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining Callback object\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epoch,logs=[]):\n        if logs.get('val_loss') < 0.3:\n            print('Validation Accuracy Achieved')\n            self.model.stop_training=True\ncallback=myCallback()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting on Training Data\nmodel.reset_states()\nmodel.reset_metrics()\nhistory=model.fit(np.array(trainData),np.array(trainLabels),epochs=10,steps_per_epoch=37499//64,\n                  validation_data=(np.array(validData),np.array(validLabels)),callbacks=[callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displays Validation and Training Loss to manually observe overfitting\nplt.plot(np.arange(1,11),history.history['val_loss'],label='Validation Loss')\nplt.plot(np.arange(1,11),history.history['loss'],label='Training Loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displays Test Image\nplt.imshow(test_images[30])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicts the image label\nprint(np.argmax(model.predict(test_images)[30]))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}